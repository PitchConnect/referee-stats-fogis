From e41278dfcbd577ca359c6d7a9713e28bfe9a3c80 Mon Sep 17 00:00:00 2001
From: Bartek Svaberg <barteksvaberg@Barteks-MacBook-Pro.local>
Date: Sun, 20 Apr 2025 22:54:39 +0200
Subject: [PATCH 1/8] #16: Implement data import functionality for FOGIS JSON
 data

---
 referee_stats_fogis/cli.py           |  71 ++-
 referee_stats_fogis/core/importer.py | 880 ++++++++++++++++++++++++++-
 2 files changed, 933 insertions(+), 18 deletions(-)

diff --git a/referee_stats_fogis/cli.py b/referee_stats_fogis/cli.py
index e6f5d0d..fefc3e0 100644
--- a/referee_stats_fogis/cli.py
+++ b/referee_stats_fogis/cli.py
@@ -38,8 +38,61 @@ def import_command(args: argparse.Namespace) -> int:
         Exit code
     """
     print(f"Importing data from {args.file}")
-    # Implementation would go here
-    return 0
+
+    if args.dry_run:
+        print("Dry run mode: No changes will be made to the database")
+
+    from referee_stats_fogis.core.importer import DataImporter
+    from referee_stats_fogis.utils.file_utils import read_json, read_csv
+
+    try:
+        # First check if the file exists and can be read
+        if args.file.lower().endswith(".csv"):
+            data = read_csv(args.file)
+            if not data:
+                print("CSV file is empty or could not be parsed")
+                return 1
+        elif args.file.lower().endswith(".json"):
+            data = read_json(args.file)
+            if not data:
+                print("JSON file is empty or could not be parsed")
+                return 1
+        else:
+            print(f"Unsupported file format: {args.file}")
+            print("Supported formats: .csv, .json")
+            return 1
+
+        # If it's a dry run, just print some info about the data
+        if args.dry_run:
+            if args.file.lower().endswith(".csv"):
+                print(f"CSV file contains {len(data)} records")
+                if data and len(data) > 0:
+                    print("Sample fields:", list(data[0].keys()))
+            elif args.file.lower().endswith(".json"):
+                if isinstance(data, list):
+                    print(f"JSON file contains {len(data)} records")
+                    if data and len(data) > 0 and "__type" in data[0]:
+                        print(f"Data type: {data[0]['__type']}")
+                elif isinstance(data, dict):
+                    print("JSON file contains a single record")
+                    if "__type" in data:
+                        print(f"Data type: {data['__type']}")
+            return 0
+
+        # Otherwise, import the data
+        with DataImporter() as importer:
+            if args.file.lower().endswith(".csv"):
+                count = importer.import_from_csv(args.file)
+            elif args.file.lower().endswith(".json"):
+                count = importer.import_from_json(args.file)
+
+            print(f"Successfully imported {count} records")
+            return 0
+    except Exception as e:
+        print(f"Error importing data: {e}")
+        import traceback
+        traceback.print_exc()
+        return 1
 
 
 def stats_command(args: argparse.Namespace) -> int:
@@ -142,8 +195,18 @@ def main(argv: list[str] | None = None) -> int:
     subparsers = parser.add_subparsers(dest="command", help="Command to run")
 
     # Import command
-    import_parser = subparsers.add_parser("import", help="Import data")
-    import_parser.add_argument("file", help="File to import")
+    import_parser = subparsers.add_parser("import", help="Import data from FOGIS")
+    import_parser.add_argument("file", help="File to import (CSV or JSON)")
+    import_parser.add_argument(
+        "--type",
+        choices=["match", "results", "events", "players", "team-staff"],
+        help="Specify the type of data being imported (optional, auto-detected from JSON content)"
+    )
+    import_parser.add_argument(
+        "--dry-run",
+        action="store_true",
+        help="Parse the file but don't modify the database"
+    )
     import_parser.set_defaults(func=import_command)
 
     # Stats command
diff --git a/referee_stats_fogis/core/importer.py b/referee_stats_fogis/core/importer.py
index 75c73c0..ebf10f5 100644
--- a/referee_stats_fogis/core/importer.py
+++ b/referee_stats_fogis/core/importer.py
@@ -1,9 +1,32 @@
 """Data import functionality for the referee stats application."""
 
+import datetime
 import logging
 from pathlib import Path
+from typing import Any, Dict, List, Optional, Union
 
-from referee_stats_fogis.data.database import Database
+from sqlalchemy.orm import Session
+
+from referee_stats_fogis.data.base import get_session
+from referee_stats_fogis.data.models import (
+    Club,
+    Competition,
+    CompetitionCategory,
+    EventType,
+    Match,
+    MatchEvent,
+    MatchParticipant,
+    MatchResult,
+    MatchTeam,
+    Person,
+    Referee,
+    RefereeAssignment,
+    RefereeRole,
+    ResultType,
+    Team,
+    TeamContact,
+    Venue,
+)
 from referee_stats_fogis.utils.file_utils import read_csv, read_json
 
 logger = logging.getLogger(__name__)
@@ -12,15 +35,25 @@ logger = logging.getLogger(__name__)
 class DataImporter:
     """Data importer for the referee stats application."""
 
-    def __init__(self, db: Database) -> None:
+    def __init__(self, session: Optional[Session] = None) -> None:
         """Initialize the data importer.
 
         Args:
-            db: Database instance
+            session: SQLAlchemy session. If None, a new session will be created.
         """
-        self.db = db
+        self.session = session or get_session()
+
+    def __enter__(self) -> "DataImporter":
+        """Enter context manager."""
+        return self
+
+    def __exit__(self, exc_type: Any, exc_val: Any, exc_tb: Any) -> None:
+        """Exit context manager."""
+        if exc_type is not None:
+            self.session.rollback()
+        self.session.close()
 
-    def import_from_csv(self, file_path: str | Path) -> int:
+    def import_from_csv(self, file_path: Union[str, Path]) -> int:
         """Import data from a CSV file.
 
         Args:
@@ -41,7 +74,7 @@ class DataImporter:
         logger.info(f"Imported {len(data)} records from CSV file")
         return len(data)
 
-    def import_from_json(self, file_path: str | Path) -> int:
+    def import_from_json(self, file_path: Union[str, Path]) -> int:
         """Import data from a JSON file.
 
         Args:
@@ -55,15 +88,834 @@ class DataImporter:
         # Read the JSON file
         data = read_json(file_path)
 
-        # Process the data
-        # This is a placeholder implementation
-        # In a real implementation, we would parse the data and insert it into the DB
-
+        # Determine the type of data and process accordingly
         record_count = 0
-        if isinstance(data, list):
-            record_count = len(data)
-        elif isinstance(data, dict):
-            record_count = 1
+
+        try:
+            if isinstance(data, list) and len(data) > 0:
+                # Check the type of data based on the first item
+                if "__type" in data[0]:
+                    data_type = data[0]["__type"]
+                    if "MatchJSON" in data_type:
+                        record_count = self._import_matches(data)
+                    elif "MatchresultatJSON" in data_type:
+                        record_count = self._import_match_results(data)
+                    elif "MatchhandelseJSON" in data_type:
+                        record_count = self._import_match_events(data)
+                    elif "MatchdeltagareJSON" in data_type:
+                        # Determine if it's players or team staff
+                        if any("arSpelandeLedare" in item for item in data):
+                            record_count = self._import_match_participants(data)
+                        else:
+                            record_count = self._import_match_participants(data)
+                    else:
+                        logger.warning(f"Unknown data type: {data_type}")
+                else:
+                    logger.warning("Data does not contain __type field")
+            elif isinstance(data, dict):
+                # Single item
+                if "__type" in data:
+                    data_type = data["__type"]
+                    if "MatchJSON" in data_type:
+                        record_count = self._import_matches([data])
+                    else:
+                        logger.warning(f"Unknown data type: {data_type}")
+                else:
+                    logger.warning("Data does not contain __type field")
+            else:
+                logger.warning(f"Unsupported data format: {type(data)}")
+
+            # Commit the changes
+            self.session.commit()
+        except Exception as e:
+            self.session.rollback()
+            logger.error(f"Error importing data: {e}")
+            raise
 
         logger.info(f"Imported {record_count} records from JSON file")
         return record_count
+
+    def _import_matches(self, data: List[Dict[str, Any]]) -> int:
+        """Import match data.
+
+        Args:
+            data: List of match data dictionaries
+
+        Returns:
+            Number of matches imported
+        """
+        logger.info(f"Importing {len(data)} matches")
+        imported_count = 0
+
+        for match_data in data:
+            try:
+                # Extract match data
+                match_id = match_data.get("matchid")
+                if not match_id:
+                    logger.warning("Match data missing matchid, skipping")
+                    continue
+
+                # Check if match already exists
+                existing_match = self.session.query(Match).filter(Match.fogis_id == str(match_id)).first()
+
+                # Process venue
+                venue = self._get_or_create_venue(match_data)
+
+                # Process competition
+                competition = self._get_or_create_competition(match_data)
+
+                # Process teams
+                home_team = self._get_or_create_team(match_data, is_home=True)
+                away_team = self._get_or_create_team(match_data, is_home=False)
+
+                # Parse date and time
+                match_date = self._parse_date(match_data.get("speldatum", ""))
+                match_time = match_data.get("avsparkstid", "")
+
+                # Create or update match
+                if existing_match:
+                    # Update existing match
+                    existing_match.match_nr = match_data.get("matchnr", "")
+                    existing_match.date = match_date
+                    existing_match.time = match_time
+                    existing_match.venue_id = venue.id if venue else None
+                    existing_match.competition_id = competition.id if competition else None
+                    existing_match.football_type_id = match_data.get("fotbollstypid", 1)
+                    existing_match.spectators = match_data.get("antalaskadare")
+                    existing_match.status = "normal"  # Default status
+                    existing_match.is_walkover = match_data.get("wo", False)
+                    match = existing_match
+                else:
+                    # Create new match
+                    match = Match(
+                        match_nr=match_data.get("matchnr", ""),
+                        date=match_date,
+                        time=match_time,
+                        venue_id=venue.id if venue else None,
+                        competition_id=competition.id if competition else None,
+                        football_type_id=match_data.get("fotbollstypid", 1),
+                        spectators=match_data.get("antalaskadare"),
+                        status="normal",  # Default status
+                        is_walkover=match_data.get("wo", False),
+                        fogis_id=str(match_id)
+                    )
+                    self.session.add(match)
+                    self.session.flush()  # Flush to get the match ID
+
+                # Create or update match teams
+                self._create_or_update_match_teams(match, home_team, away_team)
+
+                # Process referee assignments
+                if "domaruppdraglista" in match_data and match_data["domaruppdraglista"]:
+                    self._process_referee_assignments(match, match_data["domaruppdraglista"])
+
+                imported_count += 1
+
+            except Exception as e:
+                logger.error(f"Error importing match {match_data.get('matchid')}: {e}")
+                # Continue with next match instead of failing the entire import
+                continue
+
+        return imported_count
+
+    def _get_or_create_venue(self, match_data: Dict[str, Any]) -> Optional[Venue]:
+        """Get or create a venue from match data.
+
+        Args:
+            match_data: Match data dictionary
+
+        Returns:
+            Venue object or None if venue data is missing
+        """
+        venue_id = match_data.get("anlaggningid")
+        venue_name = match_data.get("anlaggningnamn")
+
+        if not venue_id or not venue_name:
+            return None
+
+        # Check if venue already exists
+        venue = self.session.query(Venue).filter(Venue.id == venue_id).first()
+
+        if venue:
+            # Update venue data
+            venue.name = venue_name
+            venue.latitude = match_data.get("anlaggningLatitud")
+            venue.longitude = match_data.get("anlaggningLongitud")
+        else:
+            # Create new venue
+            venue = Venue(
+                id=venue_id,
+                name=venue_name,
+                latitude=match_data.get("anlaggningLatitud"),
+                longitude=match_data.get("anlaggningLongitud")
+            )
+            self.session.add(venue)
+            self.session.flush()
+
+        return venue
+
+    def _get_or_create_competition(self, match_data: Dict[str, Any]) -> Optional[Competition]:
+        """Get or create a competition from match data.
+
+        Args:
+            match_data: Match data dictionary
+
+        Returns:
+            Competition object or None if competition data is missing
+        """
+        competition_id = match_data.get("tavlingid")
+        competition_name = match_data.get("tavlingnamn")
+
+        if not competition_id or not competition_name:
+            return None
+
+        # Check if competition already exists
+        competition = self.session.query(Competition).filter(Competition.id == competition_id).first()
+
+        # Get or create competition category
+        category_id = match_data.get("tavlingskategoriid")
+        category_name = match_data.get("tavlingskategorinamn")
+
+        category = None
+        if category_id and category_name:
+            category = self.session.query(CompetitionCategory).filter(CompetitionCategory.id == category_id).first()
+
+            if not category:
+                category = CompetitionCategory(
+                    id=category_id,
+                    name=category_name
+                )
+                self.session.add(category)
+                self.session.flush()
+
+        if competition:
+            # Update competition data
+            competition.name = competition_name
+            competition.season = self._extract_season(competition_name)
+            competition.category_id = category.id if category else None
+            competition.gender_id = match_data.get("tavlingKonId")
+            competition.age_category_id = match_data.get("tavlingAlderskategori")
+            competition.fogis_id = match_data.get("tavlingnr")
+        else:
+            # Create new competition
+            competition = Competition(
+                id=competition_id,
+                name=competition_name,
+                season=self._extract_season(competition_name),
+                category_id=category.id if category else None,
+                gender_id=match_data.get("tavlingKonId"),
+                age_category_id=match_data.get("tavlingAlderskategori"),
+                fogis_id=match_data.get("tavlingnr")
+            )
+            self.session.add(competition)
+            self.session.flush()
+
+        return competition
+
+    def _get_or_create_team(self, match_data: Dict[str, Any], is_home: bool) -> Optional[Team]:
+        """Get or create a team from match data.
+
+        Args:
+            match_data: Match data dictionary
+            is_home: Whether this is the home team
+
+        Returns:
+            Team object or None if team data is missing
+        """
+        prefix = "lag1" if is_home else "lag2"
+
+        team_id = match_data.get(f"{prefix}lagid")
+        team_name = match_data.get(f"{prefix}namn")
+        club_id = match_data.get(f"{prefix}foreningid")
+
+        if not team_id or not team_name or not club_id:
+            return None
+
+        # Check if team already exists
+        team = self.session.query(Team).filter(Team.id == team_id).first()
+
+        # Get or create club
+        club = self.session.query(Club).filter(Club.id == club_id).first()
+
+        if not club:
+            club = Club(
+                id=club_id,
+                name=team_name.split(" ")[0] if " " in team_name else team_name  # Use first part of team name as club name
+            )
+            self.session.add(club)
+            self.session.flush()
+
+        if team:
+            # Update team data
+            team.name = team_name
+            team.club_id = club.id
+            team.fogis_id = str(team_id)
+        else:
+            # Create new team
+            team = Team(
+                id=team_id,
+                name=team_name,
+                club_id=club.id,
+                fogis_id=str(team_id)
+            )
+            self.session.add(team)
+            self.session.flush()
+
+        return team
+
+    def _create_or_update_match_teams(self, match: Match, home_team: Optional[Team], away_team: Optional[Team]) -> None:
+        """Create or update match teams.
+
+        Args:
+            match: Match object
+            home_team: Home team object
+            away_team: Away team object
+        """
+        if home_team:
+            # Check if match team already exists
+            home_match_team = self.session.query(MatchTeam).filter(
+                MatchTeam.match_id == match.id,
+                MatchTeam.team_id == home_team.id
+            ).first()
+
+            if home_match_team:
+                # Update match team
+                home_match_team.is_home_team = True
+            else:
+                # Create new match team
+                home_match_team = MatchTeam(
+                    match_id=match.id,
+                    team_id=home_team.id,
+                    is_home_team=True
+                )
+                self.session.add(home_match_team)
+
+        if away_team:
+            # Check if match team already exists
+            away_match_team = self.session.query(MatchTeam).filter(
+                MatchTeam.match_id == match.id,
+                MatchTeam.team_id == away_team.id
+            ).first()
+
+            if away_match_team:
+                # Update match team
+                away_match_team.is_home_team = False
+            else:
+                # Create new match team
+                away_match_team = MatchTeam(
+                    match_id=match.id,
+                    team_id=away_team.id,
+                    is_home_team=False
+                )
+                self.session.add(away_match_team)
+
+        self.session.flush()
+
+    def _process_referee_assignments(self, match: Match, referee_data: List[Dict[str, Any]]) -> None:
+        """Process referee assignments.
+
+        Args:
+            match: Match object
+            referee_data: List of referee assignment data dictionaries
+        """
+        for ref_assignment in referee_data:
+            try:
+                referee_id = ref_assignment.get("domareid")
+                person_id = ref_assignment.get("personid")
+                role_id = ref_assignment.get("domarrollid")
+
+                if not referee_id or not person_id or not role_id:
+                    logger.warning(f"Referee assignment missing required data, skipping: {ref_assignment}")
+                    continue
+
+                # Get or create person
+                person = self._get_or_create_person(ref_assignment)
+
+                # Get or create referee
+                referee = self._get_or_create_referee(referee_id, person)
+
+                # Get or create referee role
+                role = self.session.query(RefereeRole).filter(RefereeRole.id == role_id).first()
+
+                if not role:
+                    role_name = ref_assignment.get("domarrollnamn", "Unknown")
+                    role_short_name = ref_assignment.get("domarrollkortnamn", "")
+
+                    role = RefereeRole(
+                        id=role_id,
+                        name=role_name,
+                        short_name=role_short_name
+                    )
+                    self.session.add(role)
+                    self.session.flush()
+
+                # Check if assignment already exists
+                assignment = self.session.query(RefereeAssignment).filter(
+                    RefereeAssignment.match_id == match.id,
+                    RefereeAssignment.referee_id == referee.id,
+                    RefereeAssignment.role_id == role.id
+                ).first()
+
+                assignment_id = ref_assignment.get("domaruppdragid")
+
+                if assignment:
+                    # Update assignment
+                    assignment.status = ref_assignment.get("domaruppdragstatusnamn", "")
+                    if assignment_id:
+                        assignment.fogis_id = str(assignment_id)
+                else:
+                    # Create new assignment
+                    assignment = RefereeAssignment(
+                        match_id=match.id,
+                        referee_id=referee.id,
+                        role_id=role.id,
+                        status=ref_assignment.get("domaruppdragstatusnamn", ""),
+                        fogis_id=str(assignment_id) if assignment_id else None
+                    )
+                    self.session.add(assignment)
+
+            except Exception as e:
+                logger.error(f"Error processing referee assignment: {e}")
+                # Continue with next assignment instead of failing the entire import
+                continue
+
+        self.session.flush()
+
+    def _get_or_create_person(self, data: Dict[str, Any]) -> Person:
+        """Get or create a person from data.
+
+        Args:
+            data: Person data dictionary
+
+        Returns:
+            Person object
+        """
+        person_id = data.get("personid")
+
+        if not person_id:
+            raise ValueError("Person data missing personid")
+
+        # Check if person already exists
+        person = self.session.query(Person).filter(Person.id == person_id).first()
+
+        # Extract name parts
+        full_name = data.get("personnamn", "") or data.get("namn", "")
+        first_name = data.get("fornamn", "")
+        last_name = data.get("efternamn", "")
+
+        if not first_name and not last_name and full_name:
+            # Split full name into first and last name
+            name_parts = full_name.split(" ")
+            if len(name_parts) > 1:
+                first_name = name_parts[0]
+                last_name = " ".join(name_parts[1:])
+            else:
+                first_name = full_name
+                last_name = ""
+
+        if person:
+            # Update person data
+            person.first_name = first_name
+            person.last_name = last_name
+            person.personal_number = data.get("personnr")
+            person.email = data.get("epostadress")
+            person.phone = data.get("mobiltelefon")
+            person.address = data.get("adress")
+            person.postal_code = data.get("postnr")
+            person.city = data.get("postort")
+            person.country = data.get("land", "Sweden")
+        else:
+            # Create new person
+            person = Person(
+                id=person_id,
+                first_name=first_name,
+                last_name=last_name,
+                personal_number=data.get("personnr"),
+                email=data.get("epostadress"),
+                phone=data.get("mobiltelefon"),
+                address=data.get("adress"),
+                postal_code=data.get("postnr"),
+                city=data.get("postort"),
+                country=data.get("land", "Sweden")
+            )
+            self.session.add(person)
+            self.session.flush()
+
+        return person
+
+    def _get_or_create_referee(self, referee_id: int, person: Person) -> Referee:
+        """Get or create a referee.
+
+        Args:
+            referee_id: Referee ID
+            person: Person object
+
+        Returns:
+            Referee object
+        """
+        # Check if referee already exists
+        referee = self.session.query(Referee).filter(Referee.id == referee_id).first()
+
+        if referee:
+            # Update referee data
+            referee.person_id = person.id
+        else:
+            # Create new referee
+            referee = Referee(
+                id=referee_id,
+                person_id=person.id
+            )
+            self.session.add(referee)
+            self.session.flush()
+
+        return referee
+
+    def _parse_date(self, date_str: str) -> datetime.datetime:
+        """Parse a date string into a datetime object.
+
+        Args:
+            date_str: Date string in format YYYY-MM-DD
+
+        Returns:
+            Datetime object
+        """
+        try:
+            return datetime.datetime.strptime(date_str, "%Y-%m-%d")
+        except ValueError:
+            # Return current date if parsing fails
+            logger.warning(f"Failed to parse date: {date_str}, using current date")
+            return datetime.datetime.now()
+
+    def _extract_season(self, competition_name: str) -> str:
+        """Extract season from competition name.
+
+        Args:
+            competition_name: Competition name
+
+        Returns:
+            Season string
+        """
+        # Try to extract a year from the competition name
+        import re
+        year_match = re.search(r'\b(20\d{2})\b', competition_name)
+        if year_match:
+            return year_match.group(1)
+        return ""
+
+    def _import_match_results(self, data: List[Dict[str, Any]]) -> int:
+        """Import match results data.
+
+        Args:
+            data: List of match result data dictionaries
+
+        Returns:
+            Number of match results imported
+        """
+        logger.info(f"Importing {len(data)} match results")
+        imported_count = 0
+
+        for result_data in data:
+            try:
+                match_id = result_data.get("matchid")
+                result_type_id = result_data.get("matchresultattypid")
+
+                if not match_id or not result_type_id:
+                    logger.warning("Match result data missing required fields, skipping")
+                    continue
+
+                # Check if match exists
+                match = self.session.query(Match).filter(Match.fogis_id == str(match_id)).first()
+
+                if not match:
+                    logger.warning(f"Match with ID {match_id} not found, skipping result")
+                    continue
+
+                # Get or create result type
+                result_type = self.session.query(ResultType).filter(ResultType.id == result_type_id).first()
+
+                if not result_type:
+                    result_type_name = result_data.get("matchresultattypnamn", "Unknown")
+                    result_type = ResultType(
+                        id=result_type_id,
+                        name=result_type_name
+                    )
+                    self.session.add(result_type)
+                    self.session.flush()
+
+                # Check if result already exists
+                result_id = result_data.get("matchresultatid")
+                existing_result = None
+
+                if result_id:
+                    existing_result = self.session.query(MatchResult).filter(MatchResult.id == result_id).first()
+
+                if not existing_result:
+                    # Also check by match and result type
+                    existing_result = self.session.query(MatchResult).filter(
+                        MatchResult.match_id == match.id,
+                        MatchResult.result_type_id == result_type.id
+                    ).first()
+
+                home_goals = result_data.get("matchlag1mal", 0)
+                away_goals = result_data.get("matchlag2mal", 0)
+
+                if existing_result:
+                    # Update existing result
+                    existing_result.home_goals = home_goals
+                    existing_result.away_goals = away_goals
+                    if result_id:
+                        existing_result.fogis_id = str(result_id)
+                else:
+                    # Create new result
+                    new_result = MatchResult(
+                        id=result_id if result_id else None,
+                        match_id=match.id,
+                        result_type_id=result_type.id,
+                        home_goals=home_goals,
+                        away_goals=away_goals,
+                        fogis_id=str(result_id) if result_id else None
+                    )
+                    self.session.add(new_result)
+
+                imported_count += 1
+
+            except Exception as e:
+                logger.error(f"Error importing match result: {e}")
+                # Continue with next result instead of failing the entire import
+                continue
+
+        return imported_count
+
+    def _import_match_events(self, data: List[Dict[str, Any]]) -> int:
+        """Import match events data.
+
+        Args:
+            data: List of match event data dictionaries
+
+        Returns:
+            Number of match events imported
+        """
+        logger.info(f"Importing {len(data)} match events")
+        imported_count = 0
+
+        for event_data in data:
+            try:
+                match_id = event_data.get("matchid")
+                event_type_id = event_data.get("matchhandelsetypid")
+                participant_id = event_data.get("matchdeltagareid")
+                match_team_id = event_data.get("matchlagid")
+
+                if not match_id or not event_type_id or not participant_id or not match_team_id:
+                    logger.warning("Match event data missing required fields, skipping")
+                    continue
+
+                # Check if match exists
+                match = self.session.query(Match).filter(Match.fogis_id == str(match_id)).first()
+
+                if not match:
+                    logger.warning(f"Match with ID {match_id} not found, skipping event")
+                    continue
+
+                # Check if match participant exists
+                participant = self.session.query(MatchParticipant).filter(MatchParticipant.id == participant_id).first()
+
+                if not participant:
+                    logger.warning(f"Match participant with ID {participant_id} not found, skipping event")
+                    continue
+
+                # Check if match team exists
+                match_team = self.session.query(MatchTeam).filter(MatchTeam.id == match_team_id).first()
+
+                if not match_team:
+                    logger.warning(f"Match team with ID {match_team_id} not found, skipping event")
+                    continue
+
+                # Get or create event type
+                event_type = self.session.query(EventType).filter(EventType.id == event_type_id).first()
+
+                if not event_type:
+                    event_type_name = event_data.get("matchhandelsetypnamn", "Unknown")
+                    affects_score = event_data.get("matchhandelsetypmedforstallningsandring", False)
+
+                    # Determine event type properties based on name
+                    is_goal = "mål" in event_type_name.lower() or "goal" in event_type_name.lower()
+                    is_penalty = "straff" in event_type_name.lower() or "penalty" in event_type_name.lower()
+                    is_card = "kort" in event_type_name.lower() or "card" in event_type_name.lower()
+                    is_substitution = "byte" in event_type_name.lower() or "substitution" in event_type_name.lower()
+
+                    event_type = EventType(
+                        id=event_type_id,
+                        name=event_type_name,
+                        is_goal=is_goal,
+                        is_penalty=is_penalty,
+                        is_card=is_card,
+                        is_substitution=is_substitution,
+                        affects_score=affects_score
+                    )
+                    self.session.add(event_type)
+                    self.session.flush()
+
+                # Check if event already exists
+                event_id = event_data.get("matchhandelseid")
+                existing_event = None
+
+                if event_id:
+                    existing_event = self.session.query(MatchEvent).filter(MatchEvent.id == event_id).first()
+
+                minute = event_data.get("matchminut")
+                period = event_data.get("period")
+                comment = event_data.get("kommentar", "")
+                home_score = event_data.get("hemmamal", 0)
+                away_score = event_data.get("bortamal", 0)
+                position_x = event_data.get("planpositionx", -1)
+                position_y = event_data.get("planpositiony", -1)
+                related_event_id = event_data.get("relateradTillMatchhandelseID")
+
+                if related_event_id == 0:
+                    related_event_id = None
+
+                if existing_event:
+                    # Update existing event
+                    existing_event.match_id = match.id
+                    existing_event.participant_id = participant_id
+                    existing_event.event_type_id = event_type_id
+                    existing_event.match_team_id = match_team_id
+                    existing_event.minute = minute
+                    existing_event.period = period
+                    existing_event.comment = comment
+                    existing_event.home_score = home_score
+                    existing_event.away_score = away_score
+                    existing_event.position_x = position_x
+                    existing_event.position_y = position_y
+                    existing_event.related_event_id = related_event_id
+                    if event_id:
+                        existing_event.fogis_id = str(event_id)
+                else:
+                    # Create new event
+                    new_event = MatchEvent(
+                        id=event_id,
+                        match_id=match.id,
+                        participant_id=participant_id,
+                        event_type_id=event_type_id,
+                        match_team_id=match_team_id,
+                        minute=minute,
+                        period=period,
+                        comment=comment,
+                        home_score=home_score,
+                        away_score=away_score,
+                        position_x=position_x,
+                        position_y=position_y,
+                        related_event_id=related_event_id,
+                        fogis_id=str(event_id) if event_id else None
+                    )
+                    self.session.add(new_event)
+
+                imported_count += 1
+
+            except Exception as e:
+                logger.error(f"Error importing match event: {e}")
+                # Continue with next event instead of failing the entire import
+                continue
+
+        return imported_count
+
+    def _import_match_participants(self, data: List[Dict[str, Any]]) -> int:
+        """Import match participants data.
+
+        Args:
+            data: List of match participant data dictionaries
+
+        Returns:
+            Number of match participants imported
+        """
+        logger.info(f"Importing {len(data)} match participants")
+        imported_count = 0
+
+        for participant_data in data:
+            try:
+                match_id = participant_data.get("matchid")
+                match_team_id = participant_data.get("matchlagid")
+                player_id = participant_data.get("spelareid")
+                participant_id = participant_data.get("matchdeltagareid")
+
+                if not match_id or not match_team_id or not player_id or not participant_id:
+                    logger.warning("Match participant data missing required fields, skipping")
+                    continue
+
+                # Check if match exists
+                match = self.session.query(Match).filter(Match.fogis_id == str(match_id)).first()
+
+                if not match:
+                    logger.warning(f"Match with ID {match_id} not found, skipping participant")
+                    continue
+
+                # Check if match team exists
+                match_team = self.session.query(MatchTeam).filter(MatchTeam.id == match_team_id).first()
+
+                if not match_team:
+                    logger.warning(f"Match team with ID {match_team_id} not found, skipping participant")
+                    continue
+
+                # Get or create person
+                person = self._get_or_create_person(participant_data)
+
+                # Check if participant already exists
+                existing_participant = self.session.query(MatchParticipant).filter(MatchParticipant.id == participant_id).first()
+
+                jersey_number = participant_data.get("trojnummer")
+                is_captain = participant_data.get("lagkapten", False)
+                is_substitute = participant_data.get("ersattare", False)
+                substitution_in = participant_data.get("byte1", 0)
+                substitution_out = participant_data.get("byte2", 0)
+
+                if substitution_in == 0:
+                    substitution_in = None
+                if substitution_out == 0:
+                    substitution_out = None
+
+                is_playing_leader = participant_data.get("arSpelandeLedare", False)
+                is_responsible = participant_data.get("ansvarig", False)
+                accumulated_warnings = participant_data.get("spelareAntalAckumuleradeVarningar", 0)
+                suspension_description = participant_data.get("spelareAvstangningBeskrivning", "")
+
+                if existing_participant:
+                    # Update existing participant
+                    existing_participant.match_id = match.id
+                    existing_participant.match_team_id = match_team_id
+                    existing_participant.player_id = person.id
+                    existing_participant.jersey_number = jersey_number
+                    existing_participant.is_captain = is_captain
+                    existing_participant.is_substitute = is_substitute
+                    existing_participant.substitution_in_minute = substitution_in
+                    existing_participant.substitution_out_minute = substitution_out
+                    existing_participant.is_playing_leader = is_playing_leader
+                    existing_participant.is_responsible = is_responsible
+                    existing_participant.accumulated_warnings = accumulated_warnings
+                    existing_participant.suspension_description = suspension_description
+                else:
+                    # Create new participant
+                    new_participant = MatchParticipant(
+                        id=participant_id,
+                        match_id=match.id,
+                        match_team_id=match_team_id,
+                        player_id=person.id,
+                        jersey_number=jersey_number,
+                        is_captain=is_captain,
+                        is_substitute=is_substitute,
+                        substitution_in_minute=substitution_in,
+                        substitution_out_minute=substitution_out,
+                        is_playing_leader=is_playing_leader,
+                        is_responsible=is_responsible,
+                        accumulated_warnings=accumulated_warnings,
+                        suspension_description=suspension_description
+                    )
+                    self.session.add(new_participant)
+
+                imported_count += 1
+
+            except Exception as e:
+                logger.error(f"Error importing match participant: {e}")
+                # Continue with next participant instead of failing the entire import
+                continue
+
+        return imported_count
\ No newline at end of file
-- 
2.49.0


From 7091e290407544cf0436ce466b8bdb3b8c7a62ab Mon Sep 17 00:00:00 2001
From: Bartek Svaberg <barteksvaberg@Barteks-MacBook-Pro.local>
Date: Sun, 20 Apr 2025 22:56:17 +0200
Subject: [PATCH 2/8] #16: Add tests for data import functionality

---
 tests/unit/test_importer.py | 161 ++++++++++++++++++++++++++++--------
 1 file changed, 127 insertions(+), 34 deletions(-)

diff --git a/tests/unit/test_importer.py b/tests/unit/test_importer.py
index cf5b856..2bdc9d7 100644
--- a/tests/unit/test_importer.py
+++ b/tests/unit/test_importer.py
@@ -3,24 +3,88 @@
 import json
 import os
 import tempfile
-from unittest.mock import MagicMock
+from unittest import mock
 
 import pytest
+from sqlalchemy.orm import Session
 
 from referee_stats_fogis.core.importer import DataImporter
-from referee_stats_fogis.data.database import Database
+from referee_stats_fogis.data.models import (
+    Competition,
+    Match,
+    MatchResult,
+    Person,
+    Referee,
+    RefereeAssignment,
+    Venue,
+)
 
 
 @pytest.fixture
-def mock_db() -> MagicMock:
-    """Create a mock database."""
-    return MagicMock(spec=Database)
+def mock_session() -> mock.MagicMock:
+    """Create a mock database session."""
+    return mock.MagicMock(spec=Session)
 
 
 @pytest.fixture
-def importer(mock_db: MagicMock) -> DataImporter:
-    """Create a data importer with a mock database."""
-    return DataImporter(mock_db)
+def importer(mock_session: mock.MagicMock) -> DataImporter:
+    """Create a data importer with a mock session."""
+    return DataImporter(mock_session)
+
+
+@pytest.fixture
+def sample_match_json():
+    """Sample match JSON data for testing."""
+    return {
+        "__type": "Svenskfotboll.Fogis.Web.FogisMobilDomarKlient.MatchJSON",
+        "matchid": 6169913,
+        "matchnr": "000026015",
+        "fotbollstypid": 1,
+        "lag1lagid": 61174,
+        "lag1foreningid": 11145,
+        "lag1namn": "Hestrafors IF",
+        "lag2lagid": 30415,
+        "lag2foreningid": 9528,
+        "lag2namn": "IF Böljan Falkenberg",
+        "anlaggningid": 29424,
+        "anlaggningnamn": "Bollevi Konstgräs",
+        "anlaggningLatitud": 57.71484,
+        "anlaggningLongitud": 12.58732,
+        "speldatum": "2025-04-11",
+        "avsparkstid": "19:00",
+        "tavlingid": 123399,
+        "tavlingnamn": "Div 2 Västra Götaland, herr 2025",
+        "tavlingskategoriid": 728,
+        "tavlingskategorinamn": "Division 2, herrar",
+        "antalaskadare": 246,
+        "domaruppdraglista": [
+            {
+                "domaruppdragid": 6850301,
+                "matchid": 6169913,
+                "domarrollid": 1,
+                "domarrollnamn": "Huvuddomare",
+                "domarrollkortnamn": "Dom",
+                "domareid": 6600,
+                "personid": 1082017,
+                "personnamn": "Test Referee",
+                "namn": "Test Referee",
+            }
+        ]
+    }
+
+
+@pytest.fixture
+def sample_result_json():
+    """Sample match result JSON data for testing."""
+    return {
+        "__type": "Svenskfotboll.Fogis.Web.FogisMobilDomarKlient.MatchresultatJSON",
+        "matchresultatid": 4660867,
+        "matchid": 6169913,
+        "matchresultattypid": 1,
+        "matchresultattypnamn": "Slutresultat",
+        "matchlag1mal": 2,
+        "matchlag2mal": 2
+    }
 
 
 def test_import_from_csv(importer: DataImporter) -> None:
@@ -41,42 +105,71 @@ def test_import_from_csv(importer: DataImporter) -> None:
         os.unlink(temp_path)
 
 
-def test_import_from_json_list(importer: DataImporter) -> None:
-    """Test importing data from a JSON file containing a list."""
+@mock.patch("referee_stats_fogis.core.importer.get_session")
+def test_import_match_json(mock_get_session, sample_match_json):
+    """Test importing match data from JSON."""
+    # Create a mock session
+    mock_session = mock.MagicMock(spec=Session)
+    mock_get_session.return_value = mock_session
+
+    # Mock query results
+    mock_session.query.return_value.filter.return_value.first.return_value = None
+
     # Create a temporary JSON file
-    with tempfile.NamedTemporaryFile(delete=False, suffix=".json") as temp_file:
-        data = [
-            {"name": "John", "age": 30, "city": "New York"},
-            {"name": "Jane", "age": 25, "city": "Boston"},
-        ]
-        temp_file.write(json.dumps(data).encode("utf-8"))
-        temp_path = temp_file.name
+    with tempfile.NamedTemporaryFile(suffix=".json", delete=False) as temp_file:
+        temp_file.write(json.dumps([sample_match_json]).encode("utf-8"))
+        temp_file_path = temp_file.name
 
     try:
         # Import the data
-        record_count = importer.import_from_json(temp_path)
+        with DataImporter(session=mock_session) as importer:
+            count = importer.import_from_json(temp_file_path)
 
-        # Check the result
-        assert record_count == 2
-    finally:
-        # Clean up
-        os.unlink(temp_path)
+        # Check that the correct number of records was imported
+        assert count == 1
+
+        # Check that the session was used correctly
+        assert mock_session.add.call_count > 0
+        assert mock_session.commit.call_count == 1
 
+    finally:
+        # Clean up the temporary file
+        os.unlink(temp_file_path)
+
+
+@mock.patch("referee_stats_fogis.core.importer.get_session")
+def test_import_result_json(mock_get_session, sample_result_json):
+    """Test importing match result data from JSON."""
+    # Create a mock session
+    mock_session = mock.MagicMock(spec=Session)
+    mock_get_session.return_value = mock_session
+
+    # Mock query results - match exists
+    mock_match = mock.MagicMock(spec=Match)
+    mock_match.id = 1
+    mock_session.query.return_value.filter.return_value.first.side_effect = [
+        mock_match,  # Match query
+        None,        # Result type query
+        None         # Result query
+    ]
 
-def test_import_from_json_dict(importer: DataImporter) -> None:
-    """Test importing data from a JSON file containing a dictionary."""
     # Create a temporary JSON file
-    with tempfile.NamedTemporaryFile(delete=False, suffix=".json") as temp_file:
-        data = {"name": "John", "age": 30, "city": "New York"}
-        temp_file.write(json.dumps(data).encode("utf-8"))
-        temp_path = temp_file.name
+    with tempfile.NamedTemporaryFile(suffix=".json", delete=False) as temp_file:
+        temp_file.write(json.dumps([sample_result_json]).encode("utf-8"))
+        temp_file_path = temp_file.name
 
     try:
         # Import the data
-        record_count = importer.import_from_json(temp_path)
+        with DataImporter(session=mock_session) as importer:
+            count = importer.import_from_json(temp_file_path)
+
+        # Check that the correct number of records was imported
+        assert count == 1
+
+        # Check that the session was used correctly
+        assert mock_session.add.call_count > 0
+        assert mock_session.commit.call_count == 1
 
-        # Check the result
-        assert record_count == 1
     finally:
-        # Clean up
-        os.unlink(temp_path)
+        # Clean up the temporary file
+        os.unlink(temp_file_path)
-- 
2.49.0


From b45d1df618603f1558329cac64932807565fc157 Mon Sep 17 00:00:00 2001
From: Bartek Svaberg <barteksvaberg@Barteks-MacBook-Pro.local>
Date: Sun, 20 Apr 2025 22:57:50 +0200
Subject: [PATCH 3/8] #16: Fix type hints in config.py for Python 3.9
 compatibility

---
 referee_stats_fogis/config.py | 10 +++++-----
 1 file changed, 5 insertions(+), 5 deletions(-)

diff --git a/referee_stats_fogis/config.py b/referee_stats_fogis/config.py
index bdaa09a..c48f068 100644
--- a/referee_stats_fogis/config.py
+++ b/referee_stats_fogis/config.py
@@ -2,7 +2,7 @@
 
 import os
 from pathlib import Path
-from typing import Any
+from typing import Any, Dict, Optional, Union
 
 import yaml
 
@@ -10,17 +10,17 @@ import yaml
 class Config:
     """Configuration manager for the application."""
 
-    def __init__(self, config_path: Path | None = None) -> None:
+    def __init__(self, config_path: Optional[Path] = None) -> None:
         """Initialize the configuration manager.
 
         Args:
             config_path: Path to the configuration file. If None, uses default
                 locations.
         """
-        self.config: dict[str, Any] = {}
+        self.config: Dict[str, Any] = {}
         self._load_config(config_path)
 
-    def _load_config(self, config_path: Path | None = None) -> None:
+    def _load_config(self, config_path: Optional[Path] = None) -> None:
         """Load configuration from file.
 
         Args:
@@ -68,7 +68,7 @@ class Config:
                 if local_file_config:
                     self._update_nested_dict(self.config, local_file_config)
 
-    def _update_nested_dict(self, d: dict[str, Any], u: dict[str, Any]) -> None:
+    def _update_nested_dict(self, d: Dict[str, Any], u: Dict[str, Any]) -> None:
         """Update a nested dictionary with another nested dictionary.
 
         Args:
-- 
2.49.0


From c65a491c33e2a1f8a51a17785c2388618ae4d735 Mon Sep 17 00:00:00 2001
From: Bartek Svaberg <barteksvaberg@Barteks-MacBook-Pro.local>
Date: Sun, 20 Apr 2025 22:58:26 +0200
Subject: [PATCH 4/8] #16: Fix type hints in base.py for Python 3.9
 compatibility

---
 referee_stats_fogis/data/base.py | 6 +++---
 1 file changed, 3 insertions(+), 3 deletions(-)

diff --git a/referee_stats_fogis/data/base.py b/referee_stats_fogis/data/base.py
index 8c9cddf..b5ec71e 100644
--- a/referee_stats_fogis/data/base.py
+++ b/referee_stats_fogis/data/base.py
@@ -1,6 +1,6 @@
 """Base classes for SQLAlchemy models."""
 
-from typing import Any
+from typing import Any, Optional
 
 from sqlalchemy import create_engine
 from sqlalchemy.ext.declarative import declarative_base
@@ -15,7 +15,7 @@ Base = declarative_base()
 _SessionFactory = None
 
 
-def get_engine(db_url: str | None = None) -> Any:
+def get_engine(db_url: Optional[str] = None) -> Any:
     """Get a SQLAlchemy engine.
 
     Args:
@@ -42,7 +42,7 @@ def get_engine(db_url: str | None = None) -> Any:
     return create_engine(db_url, echo=config.get("database.echo", False))
 
 
-def init_db(db_url: str | None = None) -> None:
+def init_db(db_url: Optional[str] = None) -> None:
     """Initialize the database.
 
     Args:
-- 
2.49.0


From b5035675560d7cf3ed4a9bf50933679c31b0cbb7 Mon Sep 17 00:00:00 2001
From: Bartek Svaberg <barteksvaberg@Barteks-MacBook-Pro.local>
Date: Sun, 20 Apr 2025 23:03:30 +0200
Subject: [PATCH 5/8] #16: Fix type hints in file_utils.py for Python 3.9
 compatibility

---
 referee_stats_fogis/utils/file_utils.py | 14 +++++++-------
 1 file changed, 7 insertions(+), 7 deletions(-)

diff --git a/referee_stats_fogis/utils/file_utils.py b/referee_stats_fogis/utils/file_utils.py
index 8ff6591..389a49a 100644
--- a/referee_stats_fogis/utils/file_utils.py
+++ b/referee_stats_fogis/utils/file_utils.py
@@ -3,10 +3,10 @@
 import csv
 import json
 from pathlib import Path
-from typing import Any
+from typing import Any, Dict, List, Optional, Union
 
 
-def read_csv(file_path: str | Path) -> list[dict[str, str]]:
+def read_csv(file_path: Union[str, Path]) -> List[Dict[str, str]]:
     """Read a CSV file and return a list of dictionaries.
 
     Args:
@@ -21,9 +21,9 @@ def read_csv(file_path: str | Path) -> list[dict[str, str]]:
 
 
 def write_csv(
-    file_path: str | Path,
-    data: list[dict[str, Any]],
-    fieldnames: list[str] | None = None,
+    file_path: Union[str, Path],
+    data: List[Dict[str, Any]],
+    fieldnames: Optional[List[str]] = None,
 ) -> None:
     """Write a list of dictionaries to a CSV file.
 
@@ -45,7 +45,7 @@ def write_csv(
         writer.writerows(data)
 
 
-def read_json(file_path: str | Path) -> Any:
+def read_json(file_path: Union[str, Path]) -> Any:
     """Read a JSON file and return the parsed data.
 
     Args:
@@ -58,7 +58,7 @@ def read_json(file_path: str | Path) -> Any:
         return json.load(f)
 
 
-def write_json(file_path: str | Path, data: Any, indent: int = 2) -> None:
+def write_json(file_path: Union[str, Path], data: Any, indent: int = 2) -> None:
     """Write data to a JSON file.
 
     Args:
-- 
2.49.0


From 7c8ce95186a7eac33f87ab4b501014395bb4b789 Mon Sep 17 00:00:00 2001
From: Bartek Svaberg <barteksvaberg@Barteks-MacBook-Pro.local>
Date: Sun, 20 Apr 2025 23:04:33 +0200
Subject: [PATCH 6/8] #16: Fix test_import_result_json test

---
 tests/unit/test_importer.py | 14 +++++++++-----
 1 file changed, 9 insertions(+), 5 deletions(-)

diff --git a/tests/unit/test_importer.py b/tests/unit/test_importer.py
index 2bdc9d7..d0a5ff4 100644
--- a/tests/unit/test_importer.py
+++ b/tests/unit/test_importer.py
@@ -147,11 +147,15 @@ def test_import_result_json(mock_get_session, sample_result_json):
     # Mock query results - match exists
     mock_match = mock.MagicMock(spec=Match)
     mock_match.id = 1
-    mock_session.query.return_value.filter.return_value.first.side_effect = [
-        mock_match,  # Match query
-        None,        # Result type query
-        None         # Result query
-    ]
+    mock_match.fogis_id = str(sample_result_json["matchid"])
+
+    # Set up the mock to return the match when queried
+    def mock_query_side_effect(*args, **kwargs):
+        mock_filter = mock.MagicMock()
+        mock_filter.first.return_value = mock_match
+        return mock_filter
+
+    mock_session.query.return_value.filter.side_effect = mock_query_side_effect
 
     # Create a temporary JSON file
     with tempfile.NamedTemporaryFile(suffix=".json", delete=False) as temp_file:
-- 
2.49.0


From d4f977386edea4410ad5de2572716dfd9a67ff6a Mon Sep 17 00:00:00 2001
From: Bartek Svaberg <barteksvaberg@Barteks-MacBook-Pro.local>
Date: Sun, 20 Apr 2025 23:04:59 +0200
Subject: [PATCH 7/8] #16: Improve test mocking for result import test

---
 tests/unit/test_importer.py | 26 ++++++++++++++++++++------
 1 file changed, 20 insertions(+), 6 deletions(-)

diff --git a/tests/unit/test_importer.py b/tests/unit/test_importer.py
index d0a5ff4..51ee0b2 100644
--- a/tests/unit/test_importer.py
+++ b/tests/unit/test_importer.py
@@ -149,13 +149,27 @@ def test_import_result_json(mock_get_session, sample_result_json):
     mock_match.id = 1
     mock_match.fogis_id = str(sample_result_json["matchid"])
 
-    # Set up the mock to return the match when queried
-    def mock_query_side_effect(*args, **kwargs):
-        mock_filter = mock.MagicMock()
-        mock_filter.first.return_value = mock_match
-        return mock_filter
+    # Create different query responses based on the queried class
+    def mock_query_side_effect(queried_class):
+        mock_query = mock.MagicMock()
 
-    mock_session.query.return_value.filter.side_effect = mock_query_side_effect
+        def mock_filter_side_effect(*args, **kwargs):
+            mock_filter = mock.MagicMock()
+
+            if queried_class == Match:
+                mock_filter.first.return_value = mock_match
+            elif queried_class == ResultType:
+                # Return None for ResultType to trigger creation of a new one
+                mock_filter.first.return_value = None
+            else:
+                mock_filter.first.return_value = None
+
+            return mock_filter
+
+        mock_query.filter.side_effect = mock_filter_side_effect
+        return mock_query
+
+    mock_session.query.side_effect = mock_query_side_effect
 
     # Create a temporary JSON file
     with tempfile.NamedTemporaryFile(suffix=".json", delete=False) as temp_file:
-- 
2.49.0


From 06d73dbf66f2e8ec0b6432cc6e911b90c8427eca Mon Sep 17 00:00:00 2001
From: Bartek Svaberg <barteksvaberg@Barteks-MacBook-Pro.local>
Date: Sun, 20 Apr 2025 23:05:22 +0200
Subject: [PATCH 8/8] #16: Add ResultType import to test file

---
 tests/unit/test_importer.py | 1 +
 1 file changed, 1 insertion(+)

diff --git a/tests/unit/test_importer.py b/tests/unit/test_importer.py
index 51ee0b2..48647c6 100644
--- a/tests/unit/test_importer.py
+++ b/tests/unit/test_importer.py
@@ -16,6 +16,7 @@ from referee_stats_fogis.data.models import (
     Person,
     Referee,
     RefereeAssignment,
+    ResultType,
     Venue,
 )
 
-- 
2.49.0

